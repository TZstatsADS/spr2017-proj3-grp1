load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/RFs_fit2_train.RData")
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/workspace_fit2.RData")
fit.1
fit.1$ntree
fit.1$mtry
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/RFs_fit1_train.RData")
fit.1$mtry
fit.1$ntree
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/workspace_fit2.RData")
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/workspace_fit2.RData")
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/RFs_fit2_train.RData")
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1")
library(knitr)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1")
ggplot(data = data.frame(cv.error)) + geom_point(aes(x = 1:K, y = cv.error), color = "blue")
library(knitr)
library(randomForest)
library(ggplot2)
ggplot(data = data.frame(cv.error)) + geom_point(aes(x = 1:K, y = cv.error), color = "blue")
best <- which.min(cv.error)
system.time(fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70, doBest = TRUE))
fit.1$ntree
summary(fit.1)
fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70, doBest = TRUE)
fit.1$ntree
?tureRF
?tuneRF
system.time(fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntreeTry = 70, doBest = TRUE))
fit.1$ntree
system.time(fit.1 <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntreeTry = 70, doBest = FALSE))
fit.1
randomForest(fit.1)
randomForest(fit.1, ntree = 70)
?randomForest
randomForest(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70)
randomForest(x.train[s != best,], as.factor(y.train[s != best]), ntree = 500)
test <- tuneRF(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70)
test
predict(test, x.train)
test <- randomForest(x.train[s != best,], as.factor(y.train[s != best]), ntree = 70)
pre <- predict(test, x.train)
table(pre, x.train)
head(pre)
table(pre, y.train)
mean(pre != y.train)
pre <- predict(test, x.test)
mean(pre != y.test)
test
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/RFs_fit2_train.RData")
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/workspace_fit2.RData")
cv.error
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Non-linear SVM/output/performance_cv.RData")
View(performace_svm)
load("/Users/chenyun/Desktop/GR5243/spr2017-proj3-grp1/lib/Non-linear SVM/output/fit_train.RData")
fit_train
View(performace_svm)
knitr::opts_chunk$set(echo = TRUE)
plot(candidates,performace_svm$error,main = "CV error vs different value of cost",xlab = "Margin Parameter", ylab = "Estimated Accuracy",type="b")
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1/lib/Features/GIST")
library(knitr)
library(randomForest)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1/lib/Features/GIST")
label.train <- as.vector(c(rep(0,1000), rep(1,1000)))
label.train <- as.factor(as.vector(c(rep(0,1000), rep(1,1000))))
label.train <- as.factor(as.vector(c(rep(0,1000), rep(1,1000))))
features.1 <- read.csv("chickf.csv", header = F) ## label 0
getwd()
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1/lib/Features/GIST")
features.1 <- read.csv("chickf.csv", header = F) ## label 0
features.2 <- read.csv("dogf.csv", header = F) ## label 1
features <- rbind(features.1, features.2)
seed = 0 # set seed
run.cv=TRUE # run cross-validation on the training set
K <- 5 # number of CV folds
run.feature.train = TRUE # process features for training set
run.test = TRUE # run evaluation on an independent test set
run.feature.test = TRUE # process features for test set
proportion = 0.75 # training set proportion
seed = 0 # set seed
#setwd("~/Desktop/GR5243/spr2017-proj3-grp1")
#label.train <- read.csv("./data/sift_labels.csv")
#features <- read.csv("./data/sift_features.csv")
label.train <- as.factor(as.vector(c(rep(0,1000), rep(1,1000))))
features.1 <- read.csv("chickf.csv", header = F) ## label 0
features.2 <- read.csv("dogf.csv", header = F) ## label 1
features <- rbind(features.1, features.2)
n <- dim(features)[1]
set.seed(seed)
index <- sample(n, n*proportion)
x.train <- features[index,]
y.train <- label.train[index]
x.test <- features[-index,]
y.test <- label.train[-index]
length(y.train)
length(y.test)
?randomForest
rf <- randomForest(x.train, y.train, ntree ntree = 200)
rf <- randomForest(x.train, y.train, ntree = 200)
rf
rf$err.rate
rf
rf$inbag
rf$ntree
rf$oob.times
rf$oob
rf$type
rf$call
rf$confusion
rf$proximity
rf$y
rf$test
rf$oob
rf
rf200 <- randomForest(x.train, y.train, ntree ntree = 200)
rf200 <- randomForest(x.train, y.train, ntree = 200)
rf300 <- randomForest(x.train, y.train, ntree = 300)
rf400 <- randomForest(x.train, y.train, ntree ntree = 400)
rf400 <- randomForest(x.train, y.train, ntree = 400)
rf300
rf300
rf400
rf500
rf500 <- randomForest(x.train, y.train, ntree = 500)
rf600 <- randomForest(x.train, y.train, ntree ntree = 600)
rf500
rf700 <- randomForest(x.train, y.train, ntree = 700)
rf200
rf300
rf400
rf500
rf700
rf600 <- randomForest(x.train, y.train, ntree = 600)
rf800 <- randomForest(x.train, y.train, ntree = 800)
rf600
rf800
rf700
rf900 <- randomForest(x.train, y.train, ntree = 900)
rf900
?tuneRF
rf <- NULL
for (i in 1:8){
rf[i] <- randomForest(x.train, y.train, ntree = i*100)
}
rf <- list()
for (i in 1:2){
rf[i] <- randomForest(x.train, y.train, ntree = i*100)
}
rf <- list()
for (i in 1:2){
rf_i <- randomForest(x.train, y.train, ntree = i*100)
}
rf_i
rm(rf_i)
mtry <- tuneRF(x.train, y.train, ntreeTry=200,
stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
mtry
mtry[,2]
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
best.m
mtry <- tuneRF(x.train, y.train, ntreeTry=600,
+        stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
mtry <- tuneRF(x.train, y.train, ntreeTry=600,
stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
mtry <- tuneRF(x.train, y.train, ntreeTry=600, trace=TRUE, plot=TRUE)
mtry <- tuneRF(x.train, y.train, ntreeTry=600, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
set.seed(0)
rf <-randomForest(x.train, y.train, mtry=best.m, importance=TRUE,ntree=600)
set.seed(0)
rf <-randomForest(x.train, y.train, mtry=best.m, importance=TRUE,ntree=600)
rf
library(ROCR)
install.packages("party")
library(ROCR)
install.packages("ROCR")
library(ROCR)
importance(rf)
varlmpPlot(rf)
?varlmp
library(randomForest)
install.packages(c("cluster", "gbm", "pbkrtest", "psych", "Rcpp", "RcppEigen", "stringi", "survival"))
varlmpPlot(rf)
varImpPlot
?varImpPlot
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1/lib/Features/GIST")
library(knitr)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1/lib/Features/GIST")
pred1 <- predict(rf, type = "prob")
pred1 <- predict(rf)
library(party)
pred1 <- predict(rf, type = "prob")
pred1 <- predict(rf, type = "prob")
varimp(rf)
pred1 <- predict(rf, x.train, type = "prob")
pred1 <- predict(rf, x.train)
rf <-randomForest(x.train, y.train, mtry=best.m, ntree=600)
library(randomForest)
library(randomForest)
library(ROCR)
library(knitr)
varImpPlot(rf)
pred1 <- predict(rf, type = "prob")
pred1
pred1 <- predict(rf)
pred1
pred1 <- predict(rf, x.train)
mean(pred1 != y.train)
mean(pred1 != y.train)
pred1
y.train
mean(pred1 == y.train)
pred1 <- predict(rf)
mean(pred1 != y.train)
pred2 <- predict(rf, x.test)
mean(pred1 != y.test)
mean(pred1 != y.train)
pred1 <- predict(rf, x.train)
mean(pred1 != y.train)
rf == x.train
predict(rf) == x.train
all.equal(predict(rf),x.train)
rf
pred1 <- predict(rf)
mean(pred1 != y.train)
pred2=predict(rf,type = "prob")
perf = prediction(pred2[,2], y.train)
perf
auc = performance(perf, "auc")
pred3 = performance(perf, "tpr","fpr")
abline(a=0,b=1,lwd=2,lty=2,col="gray")
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
cforest(income~., data=mydata, controls=cforest_control(mtry=2, mincriterion=0))
cforest(x.train, y.train, controls=cforest_control(mtry=2, mincriterion=0))
?cforest
cforest(y.train ~ x.train, controls=cforest_control(mtry=2, mincriterion=0))
cforest(y.train ~ x.train)
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
mtry
rf
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
abline(a=0,b=1,lwd=2,lty=2,col="gray")
auc = performance(perf, "auc")
auc
plot(pred3,main="ROC Curve for Random Forest",col=2,lwd=2)
if(!require("randomForest")){
install.packages("randomForest")
}
if(!require("ROCR")){
install.packages("ROCR")
}
if(!require("knitr")){
install.packages("knitr")
}
library(knitr)
library(randomForest)
library(ROCR)
library(knitr)
library(randomForest)
library(ROCR)
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "~/Desktop/GR5243/spr2017-proj3-grp1")
proportion = 0.75 # training set proportion
seed = 0 # set seed
features <- read.csv("./data/sift_features.csv")
features <- t(features)
label.train <- read.csv("./data/sift_labels.csv")
n <- dim(features)[1]
set.seed(seed)
index <- sample(n, n*proportion)
x.train <- features[index,]
y.train <- label.train[index]
label.train <- as.factor(as.vector(label.train))
View(label.train)
label.train <- as.vector(label.train)
label.train <- as.vector(label.train)
as.factor(label.train)
View(x.train)
type(index)
summary(index)
mode(index)
label.train <- as.numeric(label.train)
mode(label.train)
View(label.train)
label.train <- label.train <- as.factor(as.vector(c(rep(0,1000), rep(1,1000))))
features <- read.csv("./data/sift_features.csv")
features <- t(features)
label.train <- label.train <- as.factor(as.vector(c(rep(0,1000), rep(1,1000))))
n <- dim(features)[1]
set.seed(seed)
index <- sample(n, n*proportion)
x.train <- features[index,]
y.train <- label.train[index]
x.test <- features[-index,]
y.test <- label.train[-index]
View(features)
rf200 <- randomForest(x.train, y.train, ntree = 200)
rf300 <- randomForest(x.train, y.train, ntree = 300)
rf400 <- randomForest(x.train, y.train, ntree = 400)
rf500 <- randomForest(x.train, y.train, ntree = 500)
rf600 <- randomForest(x.train, y.train, ntree = 600)
rf700 <- randomForest(x.train, y.train, ntree = 700)
rf800 <- randomForest(x.train, y.train, ntree = 800)
# When ntree = 600 and 700, the OOB error rate stabilizes and reach minimum.
rf200
rf300
rf400
rf500
rf600
rf700
rf800
rf900 <- randomForest(x.train, y.train, ntree = 900)
rf900
rf200
rf300
rf400
rf500
rf600
rf700
rf800
rf500 <- randomForest(x.train, y.train, ntree = 500)
rf500
rf600
rf700
rf800
rf200
rf300
rf400
rf500
rf600
rf700
rf800
rf900
rf800
set.seed(0)
rf <-randomForest(x.train, y.train, mtry=best.m, importance = T, ntree=800)
mtry <- tuneRF(x.train, y.train, ntreeTry=800, stepFactor=1.5,improve=0.01, trace=TRUE, plot=TRUE)
pred1 <- predict(rf)
library(randomForest)
library(ROCR)
library(knitr)
pred1 <- predict(rf)
best.m <- mtry[mtry[, 2] == min(mtry[, 2]), 1]
set.seed(0)
rf <-randomForest(x.train, y.train, mtry=best.m, importance = T, ntree=800)
pred1 <- predict(rf)
mean(pred1 != y.train)
mtry
save.image("~/Desktop/GR5243/spr2017-proj3-grp1/lib/Random_Forests/output/Final_RFs.RData")
